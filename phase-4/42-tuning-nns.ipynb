{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 42: Tuning Neural Networks\n",
    "\n",
    "1. Pretrained networks\n",
    "2. Using GridSearch/Talos for finding optimal parameter combinations\n",
    "3. Saving your neural network to disk\n",
    "4. Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pretrained networks\n",
    "\n",
    "* A pretrained network (also known as a convolutional base for CNNs) consists of layers that have already been trained on typically general data\n",
    "* For images, these layers have already learned general patterns, textures, colors, etc. such that when you feed in your training data, certain features can immediately be detected. This part is **feature extraction**.\n",
    "* You typically add your own final layers to train the network to classify/regress based on your problem. This component is **fine tuning**\n",
    "\n",
    "Here are the pretrained models that exist within Keras: https://keras.io/api/applications/\n",
    "\n",
    "To demonstrate the utility of pretrained networks, we'll compare model performance between a baseline model and a model using a pretrained network (VGG19)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from tensorflow.keras.applications import VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Pretrained Layers\n",
    "\n",
    "VGG19: https://keras.io/api/applications/vgg/#vgg19-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = VGG19(weights='imagenet', \n",
    "                 include_top=True, \n",
    "                 input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pretrained = VGG19(weights='imagenet', \n",
    "                 include_top=False, \n",
    "                 input_shape=(224, 224, 3))\n",
    "\n",
    "pretrained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(pretrained)\n",
    "\n",
    "# freezing layers so they don't get retrained with your new data\n",
    "for layer in cnn.layers:\n",
    "    layer.trainable=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding our own dense layers\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(132, activation='relu'))\n",
    "cnn.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to verify that the weights are \"frozen\" \n",
    "for layer in cnn.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this you can now compile and fit your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GridSearch with Keras\n",
    "\n",
    "There are a couple ways to go about testing combinations of parameters, GridSearch style:\n",
    "* Using GridSearch: https://chrisalbon.com/deep_learning/keras/tuning_neural_network_hyperparameters/\n",
    "    * This involves creating a model object such that scikit-learn's existing GridSearch functions work with your neural net\n",
    "* Using Talos: https://autonomio.github.io/talos/#/Scan\n",
    "    * This library lets you tune without having to create the model object, and also can automatically output your parameter combination scores into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\",header=None, delimiter=\",\")\n",
    "\n",
    "# Specify the data \n",
    "X = dataset.iloc[:,0:8]\n",
    "y = dataset.iloc[:,8]\n",
    "\n",
    "# Split the data up in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_network(x_train, y_train, x_test, y_test, params):\n",
    "\n",
    "    # we build the model exactly like we would normally do it\n",
    "    model = Sequential()\n",
    "\n",
    "    # hidden layers\n",
    "    model.add(Dense(params['nodes1'], input_dim=8, activation=params['activation1']))\n",
    "    model.add(layers.Dropout(params['dropout']))\n",
    "    model.add(Dense(12, activation=params['activation2']))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, y_train, \n",
    "                        validation_data=(x_test, y_test),\n",
    "                        batch_size=50,\n",
    "                        epochs=10,\n",
    "                        verbose=0)\n",
    "\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dropout': [0.1, 0.3, 0.5], \n",
    "          'nodes1': [12, 20, 100],\n",
    "          'optimizer': ['adam', 'sgd'], \n",
    "          'activation1': ['relu', 'tanh'], \n",
    "          'activation2': ['relu', 'tanh']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = talos.Scan(X_train.values, y_train.values, params=params, model=dense_network, experiment_name='grid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.best_model(metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('grid/012021182905.csv').sort_values('val_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another Talos walkthrough: https://medium.com/swlh/how-to-perform-keras-hyperparameter-optimization-x3-faster-on-tpu-for-free-602b97812602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Saving your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# hidden layers\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=50,\n",
    "                    epochs=200,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get training and test loss/accuracy histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "training_acc = history.history['accuracy']\n",
    "test_acc = history.history['val_accuracy']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Visualize loss history\n",
    "ax1.plot(epoch_count, training_loss, 'r--')\n",
    "ax1.plot(epoch_count, test_loss, 'b-')\n",
    "ax1.legend(['Training Loss', 'Test Loss'])\n",
    "\n",
    "# Visualize accuracy  history\n",
    "ax2.plot(epoch_count, training_acc, 'r--')\n",
    "ax2.plot(epoch_count, test_acc, 'b-')\n",
    "ax2.legend(['Training Accuracy', 'Test Accuracy'])\n",
    "\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "my_model = load_model('model.h5')\n",
    "my_model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.evaluate(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recurrent Neural Networks - A Quick Overview\n",
    "\n",
    "Some examples:\n",
    "* https://towardsdatascience.com/recurrent-neural-networks-by-example-in-python-ffd204f99470\n",
    "* https://towardsdatascience.com/a-practical-guide-to-rnn-and-lstm-in-keras-980f176271bc\n",
    "* https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
